name: Collect Input and Log to CSV

on:
  schedule:
    - cron: '*/5 * * * *' 
  workflow_dispatch:
    inputs:
      log_entry:
        description: 'Input data to log'
        required: true
        default: 'default entry'
      server:
         description: 'server detail'
         required: true
         default: 'Azure'
      scheduleTime:
         description: 'enter time of execution'
         required: true
         default: $(date +"%Y-%m-%d %H:%M:%S")


permissions:
  contents: write  # Allows actions to write to the repository

jobs:
  log-input:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Append input to CSV
        run: |
          # Check if the CSV file exists, create it if not
          if [ ! -f input_log.csv ]; then
            echo "log_entry,server,scheduleTime" > input_log.csv
          fi
          # Append the input to the CSV
          echo "${{ github.event.inputs.log_entry}},${{ github.event.inputs.server }},${{ github.event.inputs.scheduleTime }}" >> input_log.csv
   
      - name: Commit changes
        run: |
          git config --local user.name "GitHub Action"
          git config --local user.email "action@github.com"
          git add input_log.csv
          git commit -m "Log input entry: ${{ github.event.inputs.log_entry }}"
          git pull
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  check-schedule:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python (required for CSV parsing and manipulation)
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Read CSV, process jobs, and remove processed entries
        id: read_csv
        run: |
         python -m pip install --upgrade pip  # Ensure pip is up-to-date
         sudo apt-get install -y xvfb
          Xvfb :99 -screen 0 1280x1024x24 &  # Start a virtual display on display :99
          export DISPLAY=:99  # Set DISPLAY environment variable to the virtual display
          sudo apt-get update
          sudo apt-get install imagemagick
         

          # File paths for the input and output CSV
          input_file = 'input_log.csv'
          output_file = 'updated_input_log.csv'

          # Read the CSV file
          with open(input_file, mode='r') as file:
              csv_reader = csv.DictReader(file)
              current_time = datetime.now()

              # Initialize a list to store jobs to run and the rows to keep
              jobs_to_run = []
              rows_to_keep = []

              # Check each row in the CSV file
              for row in csv_reader:
                  schedule_time = row['scheduleTime']
                  schedule_time_obj = datetime.strptime(schedule_time, "%Y-%m-%d %H:%M:%S")

                  # If schedule time is past or equal to current time, store it in jobs_to_run
                  if schedule_time_obj <= current_time:
                      jobs_to_run.append(row)
                  else:
                      # Keep the row for future processing if not yet due
                      rows_to_keep.append(row)

              # Output the jobs that need to run
              if jobs_to_run:
                  print(f"Jobs to run: {jobs_to_run}")
                  print(f"::set-output name=jobs_to_run::{jobs_to_run}")
              else:
                  print("No jobs need to be run at this time.")

          # Write the updated CSV with remaining rows
          with open(output_file, mode='w', newline='') as file:
              fieldnames = ['log_entry', 'server', 'scheduleTime']
              csv_writer = csv.DictWriter(file, fieldnames=fieldnames)

              # Write header and remaining rows to the new CSV
              csv_writer.writeheader()
              csv_writer.writerows(rows_to_keep)

          # Optionally, replace the old file with the updated one (if required)
          shutil.move(output_file, input_file)

      - name: Run scheduled jobs
        if: steps.read_csv.outputs.jobs_to_run != '[]'  # Check if jobs are found
        run: |
          # Get jobs to run from the output
          jobs_to_run="${{ steps.read_csv.outputs.jobs_to_run }}"
          echo "Running the scheduled jobs: $jobs_to_run"

          # Loop through the jobs and execute them
          for job in $(echo $jobs_to_run | jq -r '.[].log_entry'); do
            echo "Running job: $job"
            # Insert the actual logic to run the job (e.g., trigger a script or workflow)
          done

      - name: Handle no jobs to run
        if: steps.read_csv.outputs.jobs_to_run == '[]'  # If no jobs are due
        run: echo "No scheduled jobs to run at this time."
